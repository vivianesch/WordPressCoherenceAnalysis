---
title: "Regression Models"
author: "Viviane Schneider"
date: "27/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regression Models

1: Introduction
2: Residuals
3: Least Squares Estimation
4: Residual Variation  
5: Introduction to Multivariable Regression
6: MultiVar Examples
7: MultiVar Examples2 
8: MultiVar Examples3                      
9: Residuals Diagnostics and Variation
10: Variance Inflation Factors              
11: Overfitting and Underfitting 
12: Binary Outcomes                         
13: Count Outcomes          

#1: Introduction

Introduction to Regression Models. (Slides for this and other Data Science courses may
| be found at github https://github.com/DataScienceSpecialization/courses if you want to
| use them. They must be downloaded as a zip file and viewed locally. This lesson
| corresponds to Regression_Models/01_01_introduction.)

| This is the first lesson on Regression Models. We'll begin with the concept of
| "regression toward the mean" and illustrate it with some pioneering work of the father
| of forensic science, Sir Francis Galton.

 Sir Francis studied the relationship between heights of parents and their children. His
| work showed that parents who were taller than average had children who were also tall
| but closer to the average height. Similarly, parents who were shorter than average had
| children who were also shorter than average but less so than mom and dad. That is, they were closer to the average height. From one generation to the next the heights moved closer to the average or regressed toward the mean.

For this lesson we'll use Sir Francis's parent/child height data which we've taken the
| liberty to load for you as the variable, galton. (Data is from John Verzani's website,
| http://wiener.math.csi.cuny.edu/UsingR/.) So let's get started!

 Here is a plot of Galton's data, a set of 928 parent/child height pairs. Moms' and dads' heights were averaged together (after moms' heights were adjusted by a factor of 1.08).
| In our plot we used the R function "jitter" on the children's heights to highlight
| heights that occurred most frequently. The dark spots in each column rise from left to
| right suggesting that children's heights do depend on their parents'. Tall parents have tall children and short parents have short children.

| Here we add a red (45 degree) line of slope 1 and intercept 0 to the plot. If children
| tended to be the same height as their parents, we would expect the data to vary evenly
| about this line. We see this isn't the case. On the left half of the plot we see a
| concentration of heights above the line, and on the right half we see the concentration
| below the line.

 Now we've added a blue regression line to the plot. This is the line which has the
| minimum variation of the data around it. (For theory see the slides.) Its slope is
| greater than zero indicating that parents' heights do affect their children's. The slope
| is also less than 1 as would have been the case if children tended to be the same height
| as their parents.

 You'll notice that this plot looks a lot different than the original we displayed. Why?
| Many people are the same height to within measurement error, so points fall on top of one
| another. You can see that some circles appear darker than others. However, by using R's
| function "jitter" on the children's heights, we can spread out the data to simulate the
| measurement errors and make high frequency heights more visible.

| Now for the regression line. This is quite easy in R. The function lm (linear model)
| needs a "formula" and dataset. You can type "?formula" for more information, but, in
| simple terms, we just need to specify the dependent variable (children's heights) ~ the
| independent variable (parents' heights).

So generate the regression line and store it in the variable regrline. Type "regrline <-
| lm(child ~ parent, galton)"

> regrline <- lm(child ~ parent, galton)

| Excellent job!

  |==============================================                                   |  57%
| Now add the regression line to the plot with "abline". Make the line wide and red for
| visibility. Type "abline(regrline, lwd=3, col='red')"


 The regression line will have a slope and intercept which are estimated from data.
| Estimates are not exact. Their accuracy is gauged by theoretical techniques and expressed
| in terms of "standard error." You can use "summary(regrline)" to examine the Galton
| regression line. Do this now.







```{r}

```



```{r pressure, echo=FALSE}
plot(pressure)
```


